#pip install transformers
#pip install torch         //transformers å¥—ä»¶éœ€è¦
#pip install scikit-learn
#pip install transformers torch
#
# bert_explainer.py


#å¼•å…¥é‡è¦å¥—ä»¶Import Library
import torch                            #   PyTorch ä¸»æ¨¡çµ„               
import torch
import re
import os
import requests

from AI_Model_architecture import BertLSTM_CNN_Classifier 
from transformers import BertTokenizer


# é€™æ˜¯ä¸€å€‹å‡½å¼ï¼Œè®“ä½ è‡ªå‹•å¾ Google Drive æŠ“ä¸‹æ¨¡å‹æª”æ¡ˆ .pthã€‚
# file_id: ä½ å¾ Google Drive æ‹¿åˆ°çš„æ¨¡å‹ ID
# destination: ä½ è¦å„²å­˜çš„æœ¬åœ°æª”æ¡ˆè·¯å¾‘ï¼ˆä¾‹å¦‚ "model.pth"ï¼‰
def download_model_from_Gdrive(file_id, destination):#Model.pthé€£çµ(https://drive.google.com/file/d/19t6NlRFMc1i8bGtngRwIRtRcCmibdP9q/view?usp=drive_link)
    # urlè®Šæ•¸ç”¨ä¾†ç”¢ç”ŸçœŸæ­£çš„ã€Œç›´æ¥ä¸‹è¼‰é€£çµã€file_idé è¨­æ˜¯Googleé›²ç«¯è£¡çš„model.pthæª”æ¡ˆidï¼Œè®“ç¨‹å¼èƒ½ä¸‹è¼‰model.pth
    url = f"https://drive.google.com/uc?export=download&id={file_id}"  
    if not os.path.exists(destination):   # å¦‚æœæœ¬åœ°é‚„æ²’æœ‰é€™å€‹æª”æ¡ˆ â†’ æ‰ä¸‹è¼‰ï¼ˆé¿å…é‡è¤‡ï¼‰
        print("ğŸ“¥ Downloading model from Google Drive...")
        r = requests.get(url)             # ç”¨requestsç™¼é€GETè«‹æ±‚åˆ°Google Drive
        with open(destination, 'wb')as f: # æŠŠä¸‹è¼‰çš„æª”æ¡ˆå…§å®¹å¯«å…¥åˆ° model.pth æœ¬åœ°æª”æ¡ˆ
            f.write(r.content)
        print("âœ… Model downloaded.")     
    else:
        print("ğŸ“¦ Model already exists.")
        
# åœ¨ä½  load æ¨¡å‹ä¹‹å‰åŸ·è¡Œ
# é€™è¡Œæ˜¯ç‚ºäº†å–å¾—æ¨¡å‹å„²å­˜è·¯å¾‘ï¼Œç¢ºä¿å³ä½¿æ›ä¸åŒé›»è…¦æˆ–ä¸Šé›²éƒ¨ç½²ä¹Ÿèƒ½æ­£ç¢ºæ‰¾åˆ°æª”æ¡ˆã€‚
# ç°¡å–®è¬›ï¼šé€™è¡Œå°±æ˜¯ã€Œæ‰¾åˆ°é€™æ”¯ç¨‹å¼æ‰€åœ¨çš„è³‡æ–™å¤¾ï¼Œä¸¦æŒ‡å®šé‚£è£¡çš„ model.pth æª”æ¡ˆã€
# os.path.join(è³‡æ–™å¤¾,"model.pth")æŠŠè³‡æ–™å¤¾+æª”åã€Œå®‰å…¨åœ°åˆä½µã€ï¼Œè®Šæˆå®Œæ•´è·¯å¾‘(è·¨å¹³å°å…¼å®¹)
# __file__æ˜¯Pythonå…§å»ºè®Šæ•¸ï¼Œä»£è¡¨ã€Œç›®å‰é€™æ”¯ç¨‹å¼ç¢¼çš„æª”æ¡ˆè·¯å¾‘ã€
# os.path.dirname(__file__)å–å¾—é€™æ”¯.py æª”çš„ã€Œè³‡æ–™å¤¾è·¯å¾‘ã€
model_path = os.path.join(os.path.dirname(__file__), "model.pth")#åŠŸèƒ½èªªæ˜ï¼š

download_model_from_Gdrive("19t6NlRFMc1i8bGtngRwIRtRcCmibdP9q", model_path)

# è£ç½®é¸æ“‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# åˆå§‹åŒ–æ¨¡å‹æ¶æ§‹ä¸¦è¼‰å…¥è¨“ç·´æ¬Šé‡
model = BertLSTM_CNN_Classifier()

# é€™è¡Œçš„åŠŸèƒ½æ˜¯ï¼šã€Œå¾ model_pathæŠŠ.pth æ¬Šé‡æª”æ¡ˆè®€é€²ä¾†ï¼Œè¼‰å…¥é€²æ¨¡å‹è£¡ã€ã€‚
# model.load_state_dict(...)æŠŠä¸Šé¢è¼‰å…¥çš„æ¬Šé‡ã€Œå¥—é€²æ¨¡å‹æ¶æ§‹è£¡ã€
# torch.load(...)è¼‰å…¥.pth æ¬Šé‡æª”æ¡ˆï¼Œæœƒè®Šæˆä¸€ä»½ Python å­—å…¸
# map_location=deviceæŒ‡å®šæ¨¡å‹è¼‰å…¥åˆ° CPU é‚„æ˜¯ GPUï¼Œé¿å…å ±éŒ¯
model.load_state_dict(torch.load(model_path, map_location=device))

model.to(device)

# é€™æ˜¯PyTorchä¸­çš„ã€Œæ¨è«–æ¨¡å¼ã€è¨­å®š
# model.eval()æ¨¡å‹è™•æ–¼æ¨è«–ç‹€æ…‹ï¼ˆé—œæ‰ Dropout ç­‰éš¨æ©Ÿæ“ä½œï¼‰
# åªè¦æ˜¯ç”¨ä¾†ã€Œé æ¸¬ã€è€Œä¸æ˜¯è¨“ç·´ï¼Œä¸€å®šè¦åŠ  .eval()ï¼
model.eval()

# åˆå§‹åŒ– tokenizerï¼ˆä¸è¦å¾ build_bert_inputs ä¸­å–ï¼‰
tokenizer = BertTokenizer.from_pretrained("ckiplab/bert-base-chinese")

all_preds = []
all_labels = []

def predict_single_sentence(model, tokenizer, sentence, max_len=256):
    model.eval()
    with torch.no_grad():
        # æ¸…æ´—æ–‡å­—
        sentence = re.sub(r"\s+", "", sentence)
        sentence = re.sub(r"[^\u4e00-\u9fffA-Za-z0-9ã€‚ï¼Œï¼ï¼Ÿ]", "", sentence)

        # ç·¨ç¢¼
        encoded = tokenizer(sentence,
                            return_tensors="pt",
                            truncation=True,
                            padding="max_length",
                            max_length=max_len)

        input_ids = encoded["input_ids"].to(device)
        attention_mask = encoded["attention_mask"].to(device)
        token_type_ids = encoded["token_type_ids"].to(device)

        # é æ¸¬
        output = model(input_ids, attention_mask, token_type_ids)
        prob = output.item()
        label = int(prob > 0.5)

        # é¢¨éšªåˆ†ç´šé¡¯ç¤º
        if prob > 0.9:
            risk = "ğŸ”´ é«˜é¢¨éšªï¼ˆæ¥µå¯èƒ½æ˜¯è©é¨™ï¼‰"
        elif prob > 0.5:
            risk = "ğŸŸ¡ ä¸­é¢¨éšªï¼ˆå¯ç–‘ï¼‰"
        else:
            risk = "ğŸŸ¢ ä½é¢¨éšªï¼ˆæ­£å¸¸ï¼‰"

        pre_label = ""
        if label == 1:
            pre_label = 'è©é¨™'
        else:
            pre_label = 'æ­£å¸¸'
   
        print(f"\nğŸ“© è¨Šæ¯å…§å®¹ï¼š{sentence}")
        print(f"âœ… é æ¸¬çµæœï¼š{'è©é¨™' if label == 1 else 'æ­£å¸¸'}")
        print(f"ğŸ“Š ä¿¡å¿ƒå€¼ï¼š{round(prob*100, 2)}")
        print(f"âš ï¸ é¢¨éšªç­‰ç´šï¼š{risk}")
        return pre_label, prob, risk


def analyze_text(text):
    label, prob, risk = predict_single_sentence(model, tokenizer, text)
    return {
        "status": label,
        "confidence": round(prob*100, 2),  
        "suspicious_keywords": [risk]
    }

